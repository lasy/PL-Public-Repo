---
title: "Data Preparation"
author: "Laura Symul"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  bookdown::html_document2: 
    theme: flatly
    highlight: haddock
    toc: yes
    toc_float: true
    toc_depth: 5
    number_sections: true
    fig_caption: true
---



```{r data_prep setup, include = FALSE, eval = TRUE, cache = FALSE}
source("Scripts/00_setup.R")
```

```{r data_prep knitr options}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```



# Data preparation

## Load CSV, filter users, save feather files

Transform CSV into feather files

```{r data_prep load days CSV and identify users with at least one positive pregnancy test}

input_folder = paste0(IO$input_data, "Days/")
output_folder = paste0(IO$tmp_data,"Days_feather_from_csv/")
if(!dir.exists(output_folder)){dir.create(output_folder)}

files = list.files(input_folder)

tic()
cl = makeCluster(par$n_cores, outfile="")
registerDoParallel(cl)

users = foreach(file = files, .combine = c, .packages = "feather") %dopar%{
  
  days = read.csv(paste0(input_folder,file), stringsAsFactors = FALSE) 
  
  # colnames
  colnames(days)[colnames(days) == "account"] = "user_id"
  
  # identifying
  users_with_pos_preg_tests = unique(days$user_id[which(days$preg_test == 1)])
  
  # formating
  days$date = as.Date(days$date)
  # transforming first_day into a logical
  days$first_day_o = days$first_day
  days$first_day = ifelse(days$first_day == "True", TRUE, FALSE)
  
  new_file_name = gsub("csv","feather",file)
  write_feather(days, path = paste0(output_folder,new_file_name))
  #save(days, file = paste0(output_folder,new_file_name))
  
  return(users_with_pos_preg_tests)
}

stopImplicitCluster()
toc()

save(users, file = paste0(IO$tmp_data, "full_list_users_with_pos_preg_tests.Rdata"))

```


Create a user table from the list of users that ever logged a positive pregnancy test


```{r data_prep create user tables and batches}

users_df = data.frame(user_id = as.character(unique(users)), pos_preg_test = TRUE, stringsAsFactors = FALSE)
users = users_df[order(users_df$user_id),]
rm(users_df)

batch_size = min(par$max_batch_size, ceiling(nrow(users)/par$min_n_batches))
n_batches = ceiling(nrow(users)/batch_size)
users$batch = rep(1:n_batches, each = batch_size)[1:nrow(users)]

write_feather(users, path = paste0(IO$output_data, "users.feather"))
ok = file.copy(from = paste0(IO$output_data, "users.feather"), to = paste0(IO$tmp_data, "users_with_pos_preg_tests.feather"), overwrite = TRUE)

```


Filter the days table and re-organize users into batches

```{r data_prep filter days and split by batches}

input_folder = paste0(IO$tmp_data,"Days_feather_from_csv/")
tmp_folder = paste0(IO$tmp_data,"Days_filtered_split_batches/")
if(!dir.exists(tmp_folder)){dir.create(tmp_folder)}

files = list.files(input_folder)

cl = makeCluster(par$n_cores)
registerDoParallel(cl)

ok = foreach(file = files, .packages = "feather") %dopar%{
  
  full_days = read_feather(path = paste0(input_folder,file)) 
  
  # filtering
  full_days = full_days[full_days$user_id %in% users$user_id,]
  full_days$input_file_id = file
  
  # split by batches
  for(b in unique(users$batch[users$user_id %in% full_days$user_id])){
    days = full_days[full_days$user_id %in% users$user_id[users$batch == b],]
    days$batch = b
    write_feather(days, path = paste0(tmp_folder,"batch_",b,"_",file))
  }
  
}
stopImplicitCluster()

```



```{r data_prep re-assemble batches}

input_folder = paste0(IO$tmp_data,"Days_filtered_split_batches/")
output_folder = paste0(IO$output_data,"Days/")
tmp_folder = paste0(IO$tmp_data, "Days_filtered/")
if(dir.exists(input_folder)){unlink(output_folder, recursive = TRUE);dir.create(output_folder)}
if(!dir.exists(tmp_folder)){dir.create(tmp_folder)}

files = list.files(input_folder)

input_files = foreach(b = unique(users$batch), .combine = rbind) %do%{
  
  cl = makeCluster(par$n_cores)
  registerDoParallel(cl)
  
  batch_files = files[grep(paste0("batch_",b,"_day"), files)]
  
  days = foreach(file = batch_files, .combine = rbind, .packages = "feather") %dopar%{
    days = read_feather(path = paste0(input_folder,file))
    return(days)
  }
  stopImplicitCluster()
  
  # checking for duplicated rows
  d = duplicated(days)
  j = which(d)
  if(length(j)>0){
    days = days[-j,]
  }
  dim(days)
  
  write_feather(days, path = paste0(output_folder,"days_",b,".feather"))
  file.copy(from = paste0(output_folder,"days_",b,".feather"), to = paste0(tmp_folder,"days_",b,".feather"), overwrite = TRUE)
  
  input_files = aggregate(input_file_id ~ user_id, days, function(x){paste0(unique(sort(x)),collapse = "|")})
  return(input_files)
}

save(input_files, file = paste0(IO$tmp_data, "input_files.Rdata"))

```

```{r data_prep save the original input files reference into users table}

input_files = aggregate(input_file_id ~ user_id, input_files, function(x){paste0(unique(sort(x)),collapse = "|")})
users$input_files = input_files$input_file_id[match(users$user_id, input_files$user_id)]

write_feather(users, path = paste0(IO$output_data,"users.feather"))
file.copy(from = paste0(IO$output_data,"users.feather"), to = paste0(IO$tmp_data,"users_with_original_file_id.feather"), overwrite = TRUE)

```




## Create a cycles table

Note: we cannot use the cycles table that Kindara provided because the account ids are not linked between the 3 tables.

```{r data_prep checking cycles table, eval = FALSE}

# load(paste0(IO$output_data,"users.Rdata"), verbose = TRUE)

cycles_input_folder = paste0(IO$input_data,"Cycles/")
cycles_files = list.files(cycles_input_folder)

cycles = foreach(file  = cycles_files) %dopar%
{
  file  = cycles_files[3]
  cycles = read.csv(paste0(cycles_input_folder,file), stringsAsFactors = FALSE)
  dim(cycles)
  colnames(cycles)
  cycles$user_id = cycles$account
  j = which(cycles$user_id %in% users$user_id)
  length(j)
  return(cycles[j,])
}

dim(cycles)

```

We thus need to create the cycles from the days table by looking at which days have the flag `first_day`.


```{r data_prep create cycle table, eval = TRUE}

# load(paste0(IO$output_data,"users.Rdata"), verbose = TRUE)

days_input_folder = paste0(IO$output_data,"Days/")
days_files = list.files(days_input_folder)

cycles = foreach(file  = days_files, .combine = rbind, .packages = "feather") %dopar%
{
  days = read_feather(path = paste0(days_input_folder,file))
  colnames(days)
  dim(days)
  
  # creating the cycles table
  cycles = days[days$first_day, c("user_id","date")]
  colnames(cycles)[which(colnames(cycles) == "date")] = "start_date"
  cycles = cycles[order(cycles$user_id, cycles$start_date),]  
  
  j = which(cycles$user_id %in% users$user_id)
  length(j)
  cycles = cycles[j,]
  
  return(cycles)
}

dim(cycles)

write_feather(cycles, path = paste0(IO$output_data,"cycles.feather"))
file.copy(from = paste0(IO$output_data,"cycles.feather"), to = paste0(IO$tmp_data,"cycles_first_version.feather"), overwrite = TRUE)

```


We create unique cycle ID in the cycle table

```{r data_prep create cycle_nb and cycle_id in the cycles table }

# cycles = read_feather(path = paste0(IO$output_data,"users.Rdata"))
cycles = cycles[order(cycles$user_id, cycles$start_date),]

cycles$cycle_nb = ave(rep(1, nrow(cycles)), cycles$user_id, FUN = cumsum)
cycles$cycle_id = paste0(cycles$user_id, "_" ,cycles$cycle_nb)

cycles$end_date = cycles$start_date[match(cycles$cycle_id, paste0(cycles$user_id,"_",cycles$cycle_nb-1))] - 1

cycles$cycle_length = as.numeric(cycles$end_date - cycles$start_date + 1)


write_feather(cycles, path = paste0(IO$output_data,"cycles.feather"))
file.copy(from = paste0(IO$output_data,"cycles.feather"), to = paste0(IO$tmp_data,"cycles_with_nb_and_id.feather"), overwrite = TRUE)

```

And associate each row of the days to a cycle

```{r data_prep create cycle_nb and cycle_id in the days table }

days_folder = paste0(IO$output_data,"Days/")
days_tmp_folder = paste0(IO$tmp_data,"Days_with_cycle_id/")
if(!dir.exists(days_tmp_folder)){dir.create(days_tmp_folder)}

cl = makeCluster(par$n_cores)
registerDoParallel(cl)

days_files = list.files(days_folder)

ok = foreach(file  = days_files, .packages = "feather") %dopar%
{
  days = read_feather(path = paste0(days_folder,file))
  colnames(days)
  dim(days)
  
  # take the part of cycles that matches with the days users
  j = which((cycles$user_id %in% unique(days$user_id)) & (!is.na(cycles$cycle_length)))
  cycles_sub = cycles[j,]
  # for unfinished cycles, we will consider a time-window of 3 years = 1095 days after the start of the cycle to capture information about these on-going cycles.
  cycles_sub$cycle_length[which(is.na(cycles_sub$cycle_length))] = 1095
  
  # expand cycles for each day
  cycles_sub_exp = as.data.frame(lapply(cycles_sub, rep, cycles_sub$cycle_length))
  cycles_sub_exp$cycleday = ave(rep(1,nrow(cycles_sub_exp)), cycles_sub_exp$cycle_id, FUN =cumsum)
  cycles_sub_exp$date = cycles_sub_exp$start_date + (cycles_sub_exp$cycleday - 1)
  cycles_sub_exp$day_id = paste0(cycles_sub_exp$user_id, "_", cycles_sub_exp$date)
  
  
  # match days and cycles_sub_exp
  days$day_id =  paste0(days$user_id, "_", days$date)
  m = match(days$day_id, cycles_sub_exp$day_id)
  days$cycle_nb = cycles_sub_exp$cycle_nb[m]
  days$cycle_id = cycles_sub_exp$cycle_id[m]
  days$cycle_length = cycles_sub_exp$cycle_length[m]
  days$cycleday = cycles_sub_exp$cycleday[m]
  
  days$cycleday_from_end = days$cycleday - days$cycle_length - 1
  
  write_feather(days, path = paste0(days_folder, file))
  file.copy(from = paste0(days_folder, file), to = paste0(days_tmp_folder, file), overwrite = TRUE)
}

stopImplicitCluster()

```

## Aggregated cycles variable

Now we can aggregate the days table to report useful information on the cycles table


* aggregate to create the cycles table

+ user_id --v
+ cycle_id  --v
+ cycle_nb  --v
+ cycle_length  --v
+ n_days_obs  --v
+ day_last_obs [cycleday]  --v
+ n_pos_preg_test  --v
+ n_neg_preg_test  --v
+ day_first_pos_preg_test [cycleday]  --v
+ day_last_pos_preg_test [cycleday]  --v
+ n_days_obs_after_first_pos_preg_test  --v
+ last_preg_test (0, 1, -1)  --v
+ preg_test_class (0  = no preg test; 1 = at least one positive preg test ; -1 = only negative preg tests)
+ n_tot_sex  --v
+ n_prot_sex  --v
+ n_unprot_sex  --v
+ n_withdrawal  --v
+ n_insemination  --v
+ n_BBT  --v





```{r data_prep cycle_agg }

input_days_folder = paste0(IO$tmp_data,"Days_with_cycle_id/")
output_days_folder = paste0(IO$output_data,"Days/")

cl = makeCluster(par$n_cores)
registerDoParallel(cl)

days_files = list.files(input_days_folder)

cycles_agg = foreach(file  = days_files, .combine = rbind, .packages = c('plyr','dplyr','feather')) %dopar%
{
  days = read_feather(path = paste0(input_days_folder,file))
  colnames(days)
  dim(days)
  
  # take this oppotunity to change the way preg tests are encoded
  days$preg_test_o = days$preg_test
  days$preg_test[days$preg_test == 2] = -1
  
  write_feather(days, path = paste0(output_days_folder,file))
  
  # 
  cycles_agg = ddply(days, 
                     .(cycle_id), 
                     .parallel = TRUE,  # FALSE,  # TRUE
                     .fun = summarize,
                     cycle_length = min(cycle_length),
                     n_days_obs = lu(date),
                     last_obs_day = max(cycleday),
                     n_pos_preg_test = sum(preg_test == 1),
                     n_neg_preg_test = sum(preg_test == -1),
                     day_from_end_first_pos_preg_test = min( cycleday_from_end * (preg_test == 1), na.rm = TRUE),
                     day_last_pos_preg_test = max(cycleday * (preg_test == 1), na.rm = TRUE),
                     day_last_preg_test  = max(cycleday * (preg_test %in%  c(1,-1)), na.rm = TRUE),
                     n_tot_sex = sum(sex > 0, na.rm = TRUE),
                     n_prot_sex = sum(sex == 1, na.rm = TRUE),
                     n_unprot_sex =  sum(sex == 2, na.rm = TRUE),
                     n_withdrawal =  sum(sex == 3, na.rm = TRUE),
                     n_insemination = sum(sex == 4, na.rm = TRUE),
                     n_BBT = sum(!is.na(temperature), na.rm = TRUE))
  
  
  cycles_agg$day_first_pos_preg_test = NA
  j = which(cycles_agg$day_from_end_first_pos_preg_test < 0)
  cycles_agg$day_first_pos_preg_test[j] = cycles_agg$cycle_length[j] + cycles_agg$day_from_end_first_pos_preg_test[j] + 1
  
  cycles_agg$n_pos_preg_test[is.na(cycles_agg$n_pos_preg_test)] = 0
  cycles_agg$n_neg_preg_test[is.na(cycles_agg$n_neg_preg_test)] = 0
  cycles_agg$day_first_pos_preg_test[is.infinite(cycles_agg$day_first_pos_preg_test)] = 0
  cycles_agg$day_last_pos_preg_test[is.infinite(cycles_agg$day_last_pos_preg_test)] = 0
  
  # n_days_obs_after_first_pos_preg_test
  days$day_first_pos_preg_test = cycles_agg$day_first_pos_preg_test[match(days$cycle_id, cycles_agg$cycle_id)]
  days$after_first_pos_preg_test = (days$day_first_pos_preg_test > 0) & (days$cycleday > days$day_first_pos_preg_test)
  
  cycles_agg2 = aggregate(after_first_pos_preg_test ~ cycle_id, days, sum, na.rm = TRUE )
  cycles_agg$n_days_obs_after_first_pos_preg_test = cycles_agg2$after_first_pos_preg_test[match(cycles_agg$cycle_id, cycles_agg2$cycle_id)]
  
  # last_preg_test
  days$day_last_preg_test = cycles_agg$day_last_preg_test[match(days$cycle_id, cycles_agg$cycle_id)]
  cycles_agg2 = days[which(days$cycleday == days$day_last_preg_test),]
  cycles_agg$last_preg_test = cycles_agg2$preg_test[match(cycles_agg$cycle_id, cycles_agg2$cycle_id)]
  cycles_agg$last_preg_test[is.na(cycles_agg$last_preg_test)]= 0
  
  # preg_test_class
  #cycles_agg$preg_test_class = ifelse(cycles_agg$n_pos_preg_test>0,ifelse(cycles_agg$last_preg_test == 1, "pregnant","pregnancy loss"), ifelse(cycles_agg$n_neg_preg_test>0,"not pregnant", "not tested"))
  cycles_agg$preg_test_class = ifelse(cycles_agg$n_pos_preg_test>0,"pregnant", ifelse(cycles_agg$n_neg_preg_test>0,"not pregnant", "not tested"))
  
  
  return(cycles_agg)
  
}

stopImplicitCluster()

write_feather(cycles_agg, path = paste0(IO$tmp_data, "cycles_agg.feather"))

```

```{r data_prep adding cycles_agg to cycles}

column_names = colnames(cycles_agg)
column_names = column_names[-which(column_names %in% colnames(cycles))]
m = match(cycles$cycle_id, cycles_agg$cycle_id)
for(column  in column_names){
  eval(parse(text = paste0("cycles$",column,"= cycles_agg$",column,"[m]")))
  #eval(parse(text = paste0("cycles$",column,"[is.na(cycles$",column,")]= 0")))
}

write_feather(cycles, path = paste0(IO$output_data,"cycles.feather"))
file.copy(from = paste0(IO$output_data,"cycles.feather"), to = paste0(IO$tmp_data,"cycles_with_agg.feather"), overwrite = TRUE)


```




## Augmenting the user table


- with number of cycles before first positive pregnancy test
- with number of cycles after last positive pregnancy test
- with length of shortest cycle before first pregnancy test

```{r data_prep agg users}

#load(paste0(IO$tmp_data,"users_with_original_file_id.Rdata"),verbose = TRUE)

users_agg = suppressWarnings(
  ddply(cycles, 
        .(user_id), 
        .fun = summarize,
        n_cycles = max(cycle_nb, na.rm = TRUE),
        n_days_obs = sum(n_days_obs, na.rm = TRUE),
        n_pos_cycles = sum(n_pos_preg_test > 0, na.rm = TRUE),
        first_cycle_preg = min(cycle_nb[n_pos_preg_test > 0], na.rm = TRUE),
        last_cycle_preg = max(cycle_nb[n_pos_preg_test > 0], na.rm = TRUE)
        )
)

users_agg$first_cycle_preg[is.infinite(users_agg$first_cycle_preg)] =  0
users_agg$last_cycle_preg[is.infinite(users_agg$last_cycle_preg)] =  Inf


# n_obs_after_last_preg
cycles_tmp = cycles
cycles_tmp$first_cycle_preg = users_agg$first_cycle_preg[match(cycles_tmp$user_id, users_agg$user_id)]
cycles_tmp$last_cycle_preg = users_agg$last_cycle_preg[match(cycles_tmp$user_id, users_agg$user_id)]
users_agg2 = aggregate(n_days_obs ~ user_id, cycles_tmp[cycles_tmp$cycle_nb > cycles_tmp$last_cycle_preg,  ], sum, na.rm = TRUE)

users_agg$n_days_obs_after_last_preg = users_agg2$n_days_obs[match(users_agg$user_id, users_agg2$user_id)]
users_agg$n_days_obs_after_last_preg[is.na(users_agg$n_days_obs_after_first_preg )] = 0

users_agg$n_cycles_after_last_preg = users_agg$n_cycles - users_agg$last_cycle_preg
users_agg$n_cycles_after_last_preg[is.infinite(users_agg$n_cycles_after_last_preg)] = 0

# minimal cycle length before the first positive preg test
users_agg2 = aggregate(cycle_length ~ user_id, 
                       cycles_tmp[cycles_tmp$cycle_nb < cycles_tmp$first_cycle_preg,  ], 
                       min, na.rm = TRUE)

users_agg$shortest_cycle_before_first_pos_preg = users_agg2$cycle_length[match(users_agg$user_id, users_agg2$user_id)]

# adding new columns to the users table

column_names = colnames(users_agg)
column_names = column_names[-which(column_names %in% colnames(users))]
m = match(users$user_id, users_agg$user_id)
for(column  in column_names){
  eval(parse(text = paste0("users$",column,"= users_agg$",column,"[m]")))
}

write_feather(users, path = paste0(IO$output_data,"users.feather"))
file.copy(from = paste0(IO$output_data,"users.feather"), to = paste0(IO$tmp_data,"users_with_agg.feather"), overwrite = TRUE)


```


## Fill the users table

* aggregate

+ avg, median and sd of cycle_length (cycles without positive pregnancy tests)
+ avg, median and sd of cycle_length (cycles before first positive pregnancy tests)

```{r data_prep agg users cycle length stats}

#load(paste0(IO$tmp_data,"users_with_original_file_id.Rdata"),verbose = TRUE)
cycles_tmp = cycles_tmp[cycles_tmp$user_id %in% users$user_id,]

users_agg = suppressWarnings(
  ddply(cycles_tmp, 
        .(user_id), 
        .fun = summarize,
        cycle_length_no_preg_avg = mean(cycle_length[n_pos_preg_test == 0], na.rm = TRUE),
        cycle_length_no_preg_median = median(cycle_length[n_pos_preg_test == 0], na.rm = TRUE),
        cycle_length_no_preg_sd = sd(cycle_length[n_pos_preg_test == 0], na.rm = TRUE),
        cycle_length_before_preg_avg = mean(cycle_length[cycle_nb < first_cycle_preg], na.rm = TRUE),
        cycle_length_before_preg_median = median(cycle_length[cycle_nb < first_cycle_preg], na.rm = TRUE),
        cycle_length_before_preg_sd = sd(cycle_length[cycle_nb < first_cycle_preg], na.rm = TRUE))
)


column_names = colnames(users_agg)
column_names = column_names[-which(column_names %in% colnames(users))]
m = match(users$user_id, users_agg$user_id)
for(column  in column_names){
  eval(parse(text = paste0("users$",column,"= users_agg$",column,"[m]")))
}


write_feather(users, path = paste0(IO$output_data,"users.feather"))
file.copy(from = paste0(IO$output_data,"users.feather"), to = paste0(IO$tmp_data,"users_with_cycle_length_stats.feather"), overwrite = TRUE)

```










