---
title: "Data Preparation"
author: "Laura Symul"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  bookdown::html_document2: 
    theme: flatly
    highlight: haddock
    toc: yes
    toc_float: true
    toc_depth: 5
    number_sections: true
    fig_caption: true
---



```{r data_prep setup, include = FALSE, eval = TRUE, cache = FALSE}
source("Scripts/00_setup.R")
```

```{r data_prep knitr options}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```



# Data preparation

## Load CSV, filter users, save feather files

Transform CSV into feather files

```{r data_prep load days CSV and identify users with at least one positive pregnancy test}

input_folder = paste0(IO$input_data, "Days/")
output_folder = paste0(IO$tmp_data,"Days_feather_from_csv/")
if(!dir.exists(output_folder)){dir.create(output_folder)}

files = list.files(input_folder)

tic()
cl = makeCluster(par$n_cores, outfile="")
registerDoParallel(cl)

users = foreach(file = files, .combine = rbind, .packages = c("feather","readr","plyr","dplyr")) %dopar%{
  
  #days = read.csv(paste0(input_folder,file), stringsAsFactors = FALSE) 
  days = read_tsv(file = paste0(input_folder,file),
                  col_types = cols(
                    id = col_character(),
                    date = col_date(format = "%Y-%m-%d %H:%M:%S"),
                    first_day = col_logical(),
                    conception = col_logical(),
                    temperature = col_double(),
                    temp_time = col_datetime(format = ""),
                    temp_source = col_integer(),
                    questionable_temp = col_logical(),
                    no_fluid = col_logical(),
                    fluid_sticky = col_integer(),
                    fluid_creamy = col_integer(),
                    fluid_eggwhite = col_integer(),
                    fluid_watery = col_integer(),
                    cervix_height = col_integer(),
                    cervix_openness = col_integer(),
                    cervix_firmness = col_integer(),
                    opk = col_integer(),
                    preg_test = col_integer(),
                    ferning = col_skip(),
                    prg_test = col_skip(),
                    menstruation = col_integer(), 
                    spotting = col_logical(),
                    sex = col_integer(),
                    vaginal_sensation = col_skip(), #col_integer(),
                    custom = col_character(),
                    moods = col_character(),
                    symptoms = col_character()
                  ))
  
  # colnames
  colnames(days)[colnames(days) == "id"] = "user_id"
  
  # identifying
  users_with_pos_preg_tests = unique(days$user_id[which(days$preg_test == 1)])
  users = data.frame(user_id = users_with_pos_preg_tests, kindara_csv_file = file)
  
  # formating pregnancy tests
  days = mutate(days,
                preg_test_o = preg_test,
                preg_test = ifelse(preg_test == 2, -1, preg_test))
  
  
  
  new_file_name = gsub("csv","feather",file)
  write_feather(days, path = paste0(output_folder,new_file_name))
  #save(days, file = paste0(output_folder,new_file_name))
  
  return(users)
}

stopImplicitCluster()
toc()

write_feather(users, path = paste0(IO$tmp_data, "full_list_users_with_pos_preg_tests.feather"))

```


Create a user table from the list of users that ever logged a positive pregnancy test


```{r data_prep create user tables and batches}

#users = read_feather(path = paste0(IO$tmp_data, "full_list_users_with_pos_preg_tests.feather"))

users$batch = as.numeric(users$kindara_csv_file)

users_agg = ddply(users,
                  "user_id",
                  summarise,
                  kindara_csv_file = paste0(kindara_csv_file, collapse = ","),
                  batch = min(batch))

users = users_agg
users$pos_preg_test = TRUE

write_feather(users, path = paste0(IO$output_data, "users.feather"))
ok = file.copy(from = paste0(IO$output_data, "users.feather"), to = paste0(IO$tmp_data, "users_with_pos_preg_tests.feather"), overwrite = TRUE)

```


Filter the days table and re-organize users into batches

```{r data_prep filter days and split by batches}

input_folder = paste0(IO$tmp_data,"Days_feather_from_csv/")
tmp_folder = paste0(IO$tmp_data,"Days_filtered_split_batches/")
if(!dir.exists(tmp_folder)){dir.create(tmp_folder)}

files = list.files(input_folder)

cl = makeCluster(par$n_cores)
registerDoParallel(cl)

ok = foreach(file = files, .packages = "feather") %dopar%{
  
  full_days = read_feather(path = paste0(input_folder,file)) 
  
  # filtering
  full_days = full_days[full_days$user_id %in% users$user_id,]
  full_days$input_file_id = file
  
  # split by batches
  for(b in unique(users$batch[users$user_id %in% full_days$user_id])){
    days = full_days[full_days$user_id %in% users$user_id[users$batch == b],]
    days$batch = b
    write_feather(days, path = paste0(tmp_folder,"batch_",b,"_",file))
  }
  
}
stopImplicitCluster()

```



```{r data_prep re-assemble batches}

input_folder = paste0(IO$tmp_data,"Days_filtered_split_batches/")
output_folder = paste0(IO$output_data,"Days/")
tmp_folder = paste0(IO$tmp_data, "Days_filtered/")
if(dir.exists(input_folder)){unlink(output_folder, recursive = TRUE);dir.create(output_folder)}
if(!dir.exists(tmp_folder)){dir.create(tmp_folder)}

files = list.files(input_folder)

input_files = foreach(b = unique(users$batch), .combine = rbind) %do%{
  
  cl = makeCluster(par$n_cores)
  registerDoParallel(cl)
  
  batch_files = files[grep(paste0("batch_",b,"_day"), files)]
  
  days = foreach(file = batch_files, .combine = rbind, .packages = "feather") %dopar%{
    days = read_feather(path = paste0(input_folder,file))
    return(days)
  }
  stopImplicitCluster()
  
  # checking for duplicated rows
  d = duplicated(days)
  j = which(d)
  if(length(j)>0){
    days = days[-j,]
  }
  dim(days)
  
  write_feather(days, path = paste0(output_folder,"days_",b,".feather"))
  file.copy(from = paste0(output_folder,"days_",b,".feather"), to = paste0(tmp_folder,"days_",b,".feather"), overwrite = TRUE)
  
  input_files = aggregate(input_file_id ~ user_id, days, function(x){paste0(unique(sort(x)),collapse = "|")})
  return(input_files)
}

save(input_files, file = paste0(IO$tmp_data, "input_files.Rdata"))

```



## Identify cycles (and pregnancies)

```{r identify cycles}

input_folder = paste0(IO$tmp_data,"Days_filtered/")
output_folder = paste0(IO$output_data,"Days/")
tmp_folder = paste0(IO$tmp_data, "Days_filtered_with_cycles/")
if(dir.exists(input_folder)){unlink(output_folder, recursive = TRUE);dir.create(output_folder)}
if(!dir.exists(tmp_folder)){dir.create(tmp_folder)}

files = list.files(input_folder)


cl = makeCluster(par$n_cores)
registerDoParallel(cl)

foreach(file = files, .packages = c("feather","zoo","plyr","dplyr","tictoc","foreach")) %dopar%{
  
  days = read_feather(path = paste0(input_folder,file))
  o = order(days$user_id, days$date)
  days = days[o,]
  days$is_first_day = FALSE
  days = mutate(days,
                day_id = paste0(user_id, "_",date))
  
  user_ids = unique(days$user_id)
  tic()
  day_ids = foreach(user_id  = user_ids, .combine = c)%do%{
    this_user_day = days[which((days$user_id == user_id)),]
    this_user_day$day = as.numeric(this_user_day$date - min(this_user_day$date))
    
    
    cycle_starts = find_cycle_starts(this_user_day = this_user_day, debug = FALSE)
    
    # cycle_starts
    # this_user_day$day[this_user_day$first_day]
    
    # plot.tracking.history(d = this_user_day, show_tests = TRUE)
    # abline(v = this_user_day$date[this_user_day$first_day],  col = "green")
    # abline(v = this_user_day$date[match(cycle_starts,this_user_day$day)], lty = 3, col = "red")
    
    day_ids = this_user_day$day_id[this_user_day$day %in% cycle_starts]
    
    return(day_ids)
  }
  toc()
  
  days$is_first_day[days$day_id %in% day_ids] = TRUE
  
  write_feather(days, path = paste0(output_folder,file))
  file.copy(from = paste0(output_folder,file), to = paste0(tmp_folder,file), overwrite = TRUE)
}

stopImplicitCluster()

```




## Create a cycles table

We cannot use the cycles table that Kindara provided because we re-defined the cycles.
We thus create the cycles from the days table by looking at which days have the flag `is_first_day`.


```{r data_prep create cycle table, eval = TRUE}

#users = read_feather(paste0(IO$output_data,"users.feather"))

days_input_folder = paste0(IO$output_data,"Days/")
days_files = list.files(days_input_folder)

cl = makeCluster(par$n_cores)
registerDoParallel(cl)

cycles = foreach(file  = days_files, .combine = rbind, .packages = "feather") %dopar%
{
  days = read_feather(path = paste0(days_input_folder,file))
  colnames(days)
  dim(days)
  
  # creating the cycles table
  cycles = days[days$is_first_day, c("user_id","date")]
  colnames(cycles)[which(colnames(cycles) == "date")] = "start_date"
  cycles = cycles[order(cycles$user_id, cycles$start_date),]  
  
  j = which(cycles$user_id %in% users$user_id)
  length(j)
  cycles = cycles[j,]
  
  return(cycles)
}


stopImplicitCluster()

dim(cycles)

write_feather(cycles, path = paste0(IO$output_data,"cycles.feather"))
file.copy(from = paste0(IO$output_data,"cycles.feather"), to = paste0(IO$tmp_data,"cycles_first_version.feather"), overwrite = TRUE)

```


We create unique cycle ID in the cycle table

```{r data_prep create cycle_nb and cycle_id in the cycles table }

# cycles = read_feather(path = paste0(IO$output_data,"users.Rdata"))
cycles = cycles[order(cycles$user_id, cycles$start_date),]

cycles$cycle_nb = ave(rep(1, nrow(cycles)), cycles$user_id, FUN = cumsum)
cycles$cycle_id = paste0(cycles$user_id, "_" ,cycles$cycle_nb)

cycles$end_date = cycles$start_date[match(cycles$cycle_id, paste0(cycles$user_id,"_",cycles$cycle_nb-1))] - 1

cycles$cycle_length = as.numeric(cycles$end_date - cycles$start_date + 1)


write_feather(cycles, path = paste0(IO$output_data,"cycles.feather"))
file.copy(from = paste0(IO$output_data,"cycles.feather"), to = paste0(IO$tmp_data,"cycles_with_nb_and_id.feather"), overwrite = TRUE)

```

And associate each row of the days to a cycle

```{r data_prep create cycle_nb and cycle_id in the days table }

days_folder = paste0(IO$output_data,"Days/")
days_tmp_folder = paste0(IO$tmp_data,"Days_with_cycle_id/")
if(!dir.exists(days_tmp_folder)){dir.create(days_tmp_folder)}

cl = makeCluster(par$n_cores)
registerDoParallel(cl)

days_files = list.files(days_folder)

ok = foreach(file  = days_files, .packages = "feather") %dopar%
{
  days = read_feather(path = paste0(days_folder,file))
  colnames(days)
  dim(days)
  
  # take the part of cycles that matches with the days users
  j = which((cycles$user_id %in% unique(days$user_id)) & (!is.na(cycles$cycle_length)))
  cycles_sub = cycles[j,]
  # for unfinished cycles, we will consider a time-window of 3 years = 1095 days after the start of the cycle to capture information about these on-going cycles.
  cycles_sub$cycle_length[which(is.na(cycles_sub$cycle_length))] = 1095
  
  # expand cycles for each day
  cycles_sub_exp = as.data.frame(lapply(cycles_sub, rep, cycles_sub$cycle_length))
  cycles_sub_exp$cycleday = ave(rep(1,nrow(cycles_sub_exp)), cycles_sub_exp$cycle_id, FUN =cumsum)
  cycles_sub_exp$date = cycles_sub_exp$start_date + (cycles_sub_exp$cycleday - 1)
  cycles_sub_exp$day_id = paste0(cycles_sub_exp$user_id, "_", cycles_sub_exp$date)
  
  
  # match days and cycles_sub_exp
  days$day_id =  paste0(days$user_id, "_", days$date)
  m = match(days$day_id, cycles_sub_exp$day_id)
  days$cycle_nb = cycles_sub_exp$cycle_nb[m]
  days$cycle_id = cycles_sub_exp$cycle_id[m]
  days$cycle_length = cycles_sub_exp$cycle_length[m]
  days$cycleday = cycles_sub_exp$cycleday[m]
  
  days$cycleday_from_end = days$cycleday - days$cycle_length - 1
  
  write_feather(days, path = paste0(days_folder, file))
  file.copy(from = paste0(days_folder, file), to = paste0(days_tmp_folder, file), overwrite = TRUE)
}

stopImplicitCluster()

```


## Aggregated cycles variable

Now we can aggregate the days table to report useful information on the cycles table

* aggregate to create the cycles table

+ user_id --v
+ cycle_id  --v
+ cycle_nb  --v
+ cycle_length  --v
+ n_days_obs  --v
+ day_last_obs [cycleday]  --v
+ n_pos_preg_test  --v
+ n_neg_preg_test  --v
+ day_first_pos_preg_test [cycleday]  --v
+ day_last_pos_preg_test [cycleday]  --v
+ n_days_obs_after_first_pos_preg_test  --v
+ last_preg_test (0, 1, -1)  --v
+ preg_test_class (0  = no preg test; 1 = at least one positive preg test ; -1 = only negative preg tests)
+ n_tot_sex  --v
+ n_prot_sex  --v
+ n_unprot_sex  --v
+ n_withdrawal  --v
+ n_insemination  --v
+ n_BBT  --v



```{r data_prep cycle_agg }

input_days_folder = paste0(IO$tmp_data,"Days_with_cycle_id/")
output_days_folder = paste0(IO$output_data,"Days/")

cl = makeCluster(par$n_cores)
registerDoParallel(cl)

days_files = list.files(input_days_folder)

cycles_agg = foreach(file  = days_files, .combine = rbind, .packages = c('plyr','dplyr','feather')) %dopar%
{
  days = read_feather(path = paste0(input_days_folder,file))
  colnames(days)
  dim(days)
  
  # take this oppotunity to change the way preg tests are encoded
  days$preg_test_o = days$preg_test
  days$preg_test[days$preg_test == 2] = -1
  
  write_feather(days, path = paste0(output_days_folder,file))
  
  # 
  cycles_agg = ddply(days, 
                     .(cycle_id), 
                     .parallel = TRUE,  # FALSE,  # TRUE
                     .fun = summarize,
                     cycle_length = min(cycle_length),
                     n_days_obs = lu(date),
                     last_obs_day = max(cycleday),
                     n_pos_preg_test = sum(preg_test == 1),
                     n_neg_preg_test = sum(preg_test == -1),
                     day_from_end_first_pos_preg_test = min( cycleday_from_end * (preg_test == 1), na.rm = TRUE),
                     day_last_pos_preg_test = max(cycleday * (preg_test == 1), na.rm = TRUE),
                     day_last_preg_test  = max(cycleday * (preg_test %in%  c(1,-1)), na.rm = TRUE),
                     n_tot_sex = sum(sex > 0, na.rm = TRUE),
                     n_prot_sex = sum(sex == 1, na.rm = TRUE),
                     n_unprot_sex =  sum(sex == 2, na.rm = TRUE),
                     n_withdrawal =  sum(sex == 3, na.rm = TRUE),
                     n_insemination = sum(sex == 4, na.rm = TRUE),
                     n_BBT = sum(!is.na(temperature), na.rm = TRUE))
  
  
  cycles_agg$day_first_pos_preg_test = NA
  j = which(cycles_agg$day_from_end_first_pos_preg_test < 0)
  cycles_agg$day_first_pos_preg_test[j] = cycles_agg$cycle_length[j] + cycles_agg$day_from_end_first_pos_preg_test[j] + 1
  
  cycles_agg$n_pos_preg_test[is.na(cycles_agg$n_pos_preg_test)] = 0
  cycles_agg$n_neg_preg_test[is.na(cycles_agg$n_neg_preg_test)] = 0
  cycles_agg$day_first_pos_preg_test[is.infinite(cycles_agg$day_first_pos_preg_test)] = 0
  cycles_agg$day_last_pos_preg_test[is.infinite(cycles_agg$day_last_pos_preg_test)] = 0
  
  # n_days_obs_after_first_pos_preg_test
  days$day_first_pos_preg_test = cycles_agg$day_first_pos_preg_test[match(days$cycle_id, cycles_agg$cycle_id)]
  days$after_first_pos_preg_test = (days$day_first_pos_preg_test > 0) & (days$cycleday > days$day_first_pos_preg_test)
  
  cycles_agg2 = aggregate(after_first_pos_preg_test ~ cycle_id, days, sum, na.rm = TRUE )
  cycles_agg$n_days_obs_after_first_pos_preg_test = cycles_agg2$after_first_pos_preg_test[match(cycles_agg$cycle_id, cycles_agg2$cycle_id)]
  
  # last_preg_test
  days$day_last_preg_test = cycles_agg$day_last_preg_test[match(days$cycle_id, cycles_agg$cycle_id)]
  cycles_agg2 = days[which(days$cycleday == days$day_last_preg_test),]
  cycles_agg$last_preg_test = cycles_agg2$preg_test[match(cycles_agg$cycle_id, cycles_agg2$cycle_id)]
  cycles_agg$last_preg_test[is.na(cycles_agg$last_preg_test)]= 0
  
  # preg_test_class
  #cycles_agg$preg_test_class = ifelse(cycles_agg$n_pos_preg_test>0,ifelse(cycles_agg$last_preg_test == 1, "pregnant","pregnancy loss"), ifelse(cycles_agg$n_neg_preg_test>0,"not pregnant", "not tested"))
  cycles_agg$preg_test_class = ifelse(cycles_agg$n_pos_preg_test>0,"pregnant", ifelse(cycles_agg$n_neg_preg_test>0,"not pregnant", "not tested"))
  
  
  return(cycles_agg)
  
}

stopImplicitCluster()

write_feather(cycles_agg, path = paste0(IO$tmp_data, "cycles_agg.feather"))

```

```{r data_prep adding cycles_agg to cycles}

column_names = colnames(cycles_agg)
column_names = column_names[-which(column_names %in% colnames(cycles))]
m = match(cycles$cycle_id, cycles_agg$cycle_id)
for(column  in column_names){
  eval(parse(text = paste0("cycles$",column,"= cycles_agg$",column,"[m]")))
  #eval(parse(text = paste0("cycles$",column,"[is.na(cycles$",column,")]= 0")))
}

write_feather(cycles, path = paste0(IO$output_data,"cycles.feather"))
file.copy(from = paste0(IO$output_data,"cycles.feather"), to = paste0(IO$tmp_data,"cycles_with_agg.feather"), overwrite = TRUE)


```



## Augmenting the user table

- with number of cycles before first positive pregnancy test
- with number of cycles after last positive pregnancy test
- with length of shortest cycle before first pregnancy test

```{r data_prep agg users}

#load(paste0(IO$tmp_data,"users_with_original_file_id.Rdata"),verbose = TRUE)

users_agg = suppressWarnings(
  ddply(cycles, 
        .(user_id), 
        .fun = summarize,
        n_cycles = max(cycle_nb, na.rm = TRUE),
        n_days_obs = sum(n_days_obs, na.rm = TRUE),
        n_pos_cycles = sum(n_pos_preg_test > 0, na.rm = TRUE),
        first_cycle_preg = min(cycle_nb[n_pos_preg_test > 0], na.rm = TRUE),
        last_cycle_preg = max(cycle_nb[n_pos_preg_test > 0], na.rm = TRUE)
  )
)

users_agg$first_cycle_preg[is.infinite(users_agg$first_cycle_preg)] =  0
users_agg$last_cycle_preg[is.infinite(users_agg$last_cycle_preg)] =  Inf


# n_obs_after_last_preg
cycles_tmp = cycles
cycles_tmp$first_cycle_preg = users_agg$first_cycle_preg[match(cycles_tmp$user_id, users_agg$user_id)]
cycles_tmp$last_cycle_preg = users_agg$last_cycle_preg[match(cycles_tmp$user_id, users_agg$user_id)]
users_agg2 = aggregate(n_days_obs ~ user_id, cycles_tmp[cycles_tmp$cycle_nb > cycles_tmp$last_cycle_preg,  ], sum, na.rm = TRUE)

users_agg$n_days_obs_after_last_preg = users_agg2$n_days_obs[match(users_agg$user_id, users_agg2$user_id)]
users_agg$n_days_obs_after_last_preg[is.na(users_agg$n_days_obs_after_first_preg )] = 0

users_agg$n_cycles_after_last_preg = users_agg$n_cycles - users_agg$last_cycle_preg
users_agg$n_cycles_after_last_preg[is.infinite(users_agg$n_cycles_after_last_preg)] = 0

# minimal cycle length before the first positive preg test
users_agg2 = aggregate(cycle_length ~ user_id, 
                       cycles_tmp[cycles_tmp$cycle_nb < cycles_tmp$first_cycle_preg,  ], 
                       min, na.rm = TRUE)

users_agg$shortest_cycle_before_first_pos_preg = users_agg2$cycle_length[match(users_agg$user_id, users_agg2$user_id)]

# adding new columns to the users table

column_names = colnames(users_agg)
column_names = column_names[-which(column_names %in% colnames(users))]
m = match(users$user_id, users_agg$user_id)
for(column  in column_names){
  eval(parse(text = paste0("users$",column,"= users_agg$",column,"[m]")))
}

write_feather(users, path = paste0(IO$output_data,"users.feather"))
file.copy(from = paste0(IO$output_data,"users.feather"), to = paste0(IO$tmp_data,"users_with_agg.feather"), overwrite = TRUE)


```


## Fill the users table

* aggregate

+ avg, median and sd of cycle_length (cycles without positive pregnancy tests)
+ avg, median and sd of cycle_length (cycles before first positive pregnancy tests)

```{r data_prep agg users cycle length stats}

#load(paste0(IO$tmp_data,"users_with_original_file_id.Rdata"),verbose = TRUE)
cycles_tmp = cycles_tmp[cycles_tmp$user_id %in% users$user_id,]

users_agg = suppressWarnings(
  ddply(cycles_tmp, 
        .(user_id), 
        .fun = summarize,
        cycle_length_no_preg_avg = mean(cycle_length[n_pos_preg_test == 0], na.rm = TRUE),
        cycle_length_no_preg_median = median(cycle_length[n_pos_preg_test == 0], na.rm = TRUE),
        cycle_length_no_preg_sd = sd(cycle_length[n_pos_preg_test == 0], na.rm = TRUE),
        cycle_length_before_preg_avg = mean(cycle_length[cycle_nb < first_cycle_preg], na.rm = TRUE),
        cycle_length_before_preg_median = median(cycle_length[cycle_nb < first_cycle_preg], na.rm = TRUE),
        cycle_length_before_preg_sd = sd(cycle_length[cycle_nb < first_cycle_preg], na.rm = TRUE))
)


column_names = colnames(users_agg)
column_names = column_names[-which(column_names %in% colnames(users))]
m = match(users$user_id, users_agg$user_id)
for(column  in column_names){
  eval(parse(text = paste0("users$",column,"= users_agg$",column,"[m]")))
}


write_feather(users, path = paste0(IO$output_data,"users.feather"))
file.copy(from = paste0(IO$output_data,"users.feather"), to = paste0(IO$tmp_data,"users_with_cycle_length_stats.feather"), overwrite = TRUE)

```


```{r users first and last observation}

input_days_folder = paste0(IO$output_data,"Days/")

cl = makeCluster(par$n_cores)
registerDoParallel(cl)

days_files = list.files(input_days_folder)

users_agg = foreach(file  = days_files, .combine = rbind, .packages = c('plyr','dplyr','feather')) %dopar%
{
  days = read_feather(path = paste0(input_days_folder,file))
  
  users_agg = ddply(days, 
                    .(user_id), 
                    .parallel = TRUE,  # FALSE,  # TRUE
                    .fun = summarize,
                    n_pos_preg_tests = sum(preg_test == 1),
                    earliest_date = min(date, na.rm = TRUE),
                    latest_date = max(date, na.rm = TRUE))
  return(users_agg)
  
}

stopImplicitCluster()

write_feather(users_agg, path = paste0(IO$tmp_data, "users_agg_earliest_and_latest_dates.feather"))
```


```{r adding earliest and latest dates to the user table}

column_names = colnames(users_agg)
column_names = column_names[-which(column_names %in% colnames(users))]
m = match(users$user_id, users_agg$user_id)
for(column  in column_names){
  eval(parse(text = paste0("users$",column,"= users_agg$",column,"[m]")))
}

users$app_usage_duration_in_days = as.numeric(users$latest_date - users$earliest_date) 
users$app_usage_duration_in_years = users$app_usage_duration_in_days/365

write_feather(users, path = paste0(IO$output_data,"users.feather"))
file.copy(from = paste0(IO$output_data,"users.feather"), to = paste0(IO$tmp_data,"users_with_earliest_and_latest_date.feather"), overwrite = TRUE)

```


## Add the age on the users table

```{r add the age to the users table}

accounts = read_tsv(paste0(IO$input_data,"accounts.csv"))
accounts$birth_year = year(accounts$birth_day)
users$birth_year = accounts$birth_year[match(users$user_id, accounts$id)]
users$age_now = year(today()) - users$birth_year
users$age_now[(users$age_now<15)|(users$age_now>55)] = NA

write_feather(users, path = paste0(IO$output_data,"users.feather"))
file.copy(from = paste0(IO$output_data,"users.feather"), to = paste0(IO$tmp_data,"users_with_age.feather"), overwrite = TRUE)


```

```{r add the age to the cycles table}

cycles$birth_year = users$birth_year[match(cycles$user_id, users$user_id)]
cycles$current_age = year(cycles$start_date) - cycles$birth_year
cycles$current_age[(cycles$current_age<15)|(cycles$current_age>55)] = NA

users$age_at_first_pregnancy = cycles$current_age[match(paste0(users$user_id, "_",users$first_cycle_preg),cycles$cycle_id)]
  
  
write_feather(users, path = paste0(IO$output_data,"users.feather"))
file.copy(from = paste0(IO$output_data,"users.feather"), to = paste0(IO$tmp_data,"users_with_age_at_first_pregnancy.feather"), overwrite = TRUE)

write_feather(cycles, path = paste0(IO$output_data,"cycles.feather"))
file.copy(from = paste0(IO$output_data,"cycles.feather"), to = paste0(IO$tmp_data,"cycles_with_age.feather"), overwrite = TRUE)


```


